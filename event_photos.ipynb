{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "event_photos.ipynb",
      "provenance": [],
      "mount_file_id": "1zbZ277K4mz5JclvLUKnPcg_YHg47QofN",
      "authorship_tag": "ABX9TyMX+lharmyHB1GDosoqNong",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girisharoskar/springboard/blob/master/event_photos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do_1xIWZGlbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c0207b8-a917-4246-ce7d-d8758715e61f"
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "opath=\"/content/drive/My Drive/springboard\"\n",
        "os.chdir(opath)\n",
        "import pandas as pd\n",
        "import requests as re\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import json as js\n",
        "tot_images=0\n",
        "df= pd.read_csv(\"event_photo.csv\", header=None)\n",
        "img_list=[]\n",
        "for idx,a in df.iterrows():\n",
        "    #print(a['Event name'],a['Link'])\n",
        "    path=a[0]\n",
        "    url=a[2]\n",
        "    #isdir = os.path.isdir(path)  \n",
        "    \n",
        "    response=re.get(url)\n",
        "    soup=bs(response.content,'html.parser')\n",
        "    soup_js=js.loads(soup.text)\n",
        "    pages_cnt=soup_js.get('Pagination').get('TotalPages') \n",
        "    img_cnt_pp=soup_js.get('Pagination').get('TotalItems')\n",
        "    #print('URL -',url,'Images :',img_cnt_pp)\n",
        "    #print('Event: '+ a['Event name']+ ', Url - '+ url + ', Images - '+ str(img_cnt_pp))\n",
        "    tot_images=tot_images+img_cnt_pp\n",
        "    \n",
        "    npage_size='PageSize='+str(img_cnt_pp)\n",
        "    url=url.replace(\"PageSize=12\", npage_size)\n",
        "    \n",
        "    response=re.get(url)\n",
        "    soup=bs(response.content,'html.parser')\n",
        "    soup_js=js.loads(soup.text)\n",
        "    #print(url)\n",
        "    for d in soup_js['Images']:\n",
        "        imgkey=d.get('ImageKey')\n",
        "        BaseUrl=d.get('BaseUrl')\n",
        "        Serial=d.get('Serial')\n",
        "        UrlSignature=d.get('UrlSignature')\n",
        "        SEOFilename=d.get('SEOFilename')\n",
        "        Format=d.get('Format')\n",
        "        url_stg=BaseUrl+'i-'+imgkey+'/'+str(Serial)+'/'+UrlSignature+'/L/'+SEOFilename+'-L.'+Format \n",
        "        img_list.append([path,url_stg])\n",
        "\n",
        "\n",
        "i=0\n",
        "ppath=\"\"\n",
        "tot_len=len(img_list)\n",
        "lcnt=0\n",
        "#print(\"List length:\",tot_len)\n",
        "invalid_list=[]\n",
        "\n",
        "for idx,img_link in enumerate(img_list):\n",
        "  path=img_link[0]\n",
        "  fpath = opath+\"/\" + path\n",
        "  npath=path+\".zip\"\n",
        "  img_data=re.get(img_link[1]).content\n",
        "  #print(\"Value of i \",i,\"path \",fpath)\n",
        "  if ppath != path:\n",
        "    if i != 0:\n",
        "      lcnt=lcnt+i\n",
        "      print(\"Completed image download for -\",ppath)\n",
        "      print()\n",
        "      print(\"Images downloaded - , \"+str(lcnt)+\" /\",str(tot_len))\n",
        "      print()\n",
        "      i=0\n",
        "    ppath=path\n",
        "  \n",
        "  if i == 0:\n",
        "    ppath=path\n",
        "  \n",
        "  if i % 1000 == 0:\n",
        "    if i == 0 :\n",
        "      print(\"Starting images download for -\",path)\n",
        "    else:\n",
        "      print(path+ \"- , Completed \"+str(i))\n",
        "\n",
        "  if not (os.path.isdir(fpath)):\n",
        "      os.mkdir(path)\n",
        "    \n",
        "  if (re.get(img_link[1]).status_code) == 200:\n",
        "        full_path=fpath+'/image_'+str(i)+'.jpg'\n",
        "        with open(full_path,'wb+') as f:\n",
        "            f.write(img_data)\n",
        "            i+=1\n",
        "            #print(\"Valid image\")\n",
        "  else :\n",
        "        #print(\"Invalid image\")\n",
        "        #lst1.append\n",
        "        invalid_list.append((path,img_link[1]))\n",
        "    #i+=1 \n",
        "\t  #print(j)\n",
        "  if idx+1 == tot_len:\n",
        "      lcnt=lcnt+i\n",
        "      print(\"Completed image download for -\",ppath)\n",
        "      print()\n",
        "      print(\"Images downloaded - , \"+str(lcnt)+\" /\",str(tot_len))\n",
        "\n",
        "invalid_img=len(invalid_list)\n",
        "\n",
        "print(\"Completed image download for - \"+str(lcnt)+\" /\",str(tot_len))\n",
        "print()\n",
        "print(\"Total images: \",tot_len,\"Invalid images: \",invalid_img)\n",
        "print() \n",
        "\n",
        "print(\"Zipping image folder and downloading it on local system:\")\n",
        "print()\n",
        "lst=(img_list[0].unique())\n",
        "for i in lst:\n",
        "\tpath=i[0]\n",
        "\tfpath = opath+\"/\" + path\n",
        "\tnpath=path+\".zip\"\n",
        "\t!zip -r \"$path\".zip \"$fpath\"\n",
        "\tfiles.download(npath) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting images download for - BNP Endurathon 2019\n",
            "BNP Endurathon 2019- , Completed 1000\n",
            "BNP Endurathon 2019- , Completed 2000\n",
            "BNP Endurathon 2019- , Completed 3000\n",
            "BNP Endurathon 2019- , Completed 4000\n",
            "BNP Endurathon 2019- , Completed 5000\n",
            "BNP Endurathon 2019- , Completed 6000\n",
            "BNP Endurathon 2019- , Completed 7000\n",
            "BNP Endurathon 2019- , Completed 8000\n",
            "Completed image download for - BNP Endurathon 2019\n",
            "\n",
            "Images downloaded - , 8553 / 20260\n",
            "\n",
            "Starting images download for - BNP Endurathon 2018\n",
            "BNP Endurathon 2018- , Completed 1000\n",
            "BNP Endurathon 2018- , Completed 2000\n",
            "Completed image download for - BNP Endurathon 2018\n",
            "\n",
            "Images downloaded - , 11288 / 20260\n",
            "\n",
            "Starting images download for - Navy marathon 2017\n",
            "Navy marathon 2017- , Completed 1000\n",
            "Navy marathon 2017- , Completed 2000\n",
            "Navy marathon 2017- , Completed 3000\n",
            "Navy marathon 2017- , Completed 4000\n",
            "Completed image download for - Navy marathon 2017\n",
            "\n",
            "Images downloaded - , 15416 / 20260\n",
            "\n",
            "Starting images download for - Hubballi-10K-run-2016\n",
            "Hubballi-10K-run-2016- , Completed 1000\n",
            "Hubballi-10K-run-2016- , Completed 2000\n",
            "Hubballi-10K-run-2016- , Completed 3000\n",
            "Hubballi-10K-run-2016- , Completed 4000\n",
            "Completed image download for - Hubballi-10K-run-2016\n",
            "\n",
            "Images downloaded - , 20260 / 20260\n",
            "Completed image download for - 20260 / 20260\n",
            "\n",
            "Total images:  20260 Invalid images:  0\n",
            "\n",
            "Zipping image folder and downloading it on local system:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7d4da7888e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Zipping image folder and downloading it on local system:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mlst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unique'"
          ]
        }
      ]
    }
  ]
}